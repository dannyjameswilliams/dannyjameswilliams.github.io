<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Visualisation | Danny James Williams</title>
    <link>https://dannyjameswilliams.co.uk/tag/data-visualisation/</link>
      <atom:link href="https://dannyjameswilliams.co.uk/tag/data-visualisation/index.xml" rel="self" type="application/rss+xml" />
    <description>Data Visualisation</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-gb</language><lastBuildDate>Thu, 15 Oct 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://dannyjameswilliams.co.uk/images/icon_hu6de9a8f7dd4e8a8bd7c2613cf2ad59bf_37670_512x512_fill_lanczos_center_2.png</url>
      <title>Data Visualisation</title>
      <link>https://dannyjameswilliams.co.uk/tag/data-visualisation/</link>
    </image>
    
    <item>
      <title>How random are you?</title>
      <link>https://dannyjameswilliams.co.uk/post/randomchoices/</link>
      <pubDate>Thu, 15 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://dannyjameswilliams.co.uk/post/randomchoices/</guid>
      <description>


&lt;p&gt;The notion of &lt;em&gt;true random&lt;/em&gt; has perplexed scientists and statisticians for decades, if not longer. But there’s one process that we still don’t know much about - the human brain. What is it that causes our decisions to be made? When we are asked to ‘pick a random number between 1 and 10’, how ‘random’ is the number we give? Is it some complicated, deterministic signal of neurons in our brain? Or is it actually random?&lt;/p&gt;
&lt;p&gt;The following analysis and results come from a survey collected online, which obtained &lt;span class=&#34;math inline&#34;&gt;\(n = 2190\)&lt;/span&gt; participants.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you’re in a hurry, or don’t fancy reading this article, &lt;/strong&gt;&lt;a href=&#34;infographic.png&#34;&gt;&lt;strong&gt;check out the handy infographic&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;pick-a-random-number-between-1-and-10-twice&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Pick a random number between 1 and 10, twice&lt;/h2&gt;
&lt;p&gt;This is perhaps the most basic question to ask, and one that is very visually interpretable. This question was asked in two distinct ways, pictured below:&lt;/p&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;center&gt;
&lt;img src=&#34;img/questionA.png&#34; width=&#34;642&#34; style=&#34;background-color: #9ecff7; padding:2px; display: inline-block;&#34; style=&#34;display: block; margin: auto;&#34; /&gt;
&lt;figcaption&gt;
Question A.
&lt;/figcaption&gt;
&lt;/center&gt;
&lt;/figure&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;center&gt;
&lt;img src=&#34;img/questionB.png&#34; width=&#34;429&#34; style=&#34;background-color: #9ecff7; padding:2px; display: inline-block;&#34; style=&#34;display: block; margin: auto;&#34; /&gt;
&lt;figcaption&gt;
Question B.
&lt;/figcaption&gt;
&lt;/center&gt;
&lt;/figure&gt;
&lt;p&gt;These questions are asked with the following hypothesis: &lt;em&gt;does the answer input being on a scale change how people answer the question?&lt;/em&gt; In another way, if you are picking a random number, and you can see the numbers laid out in order in front of you, are you more likely to pick a number which is more central? Let’s look at the results to find out.&lt;/p&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;center&gt;
&lt;iframe height=&#34;200&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34; width=&#34;49%&#34; src=&#34;//plotly.com/~dannyjameswilliams/15.embed?autosize=true&amp;amp;link=false&amp;amp;modebar=false&#34;&gt;
&lt;/iframe&gt;
&lt;iframe height=&#34;200&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34; width=&#34;49%&#34; src=&#34;//plotly.com/~dannyjameswilliams/17.embed?autosize=true&amp;amp;link=false&amp;amp;modebar=false&#34;&gt;
&lt;/iframe&gt;
&lt;figcaption&gt;
Frequencies of choices between 1 and 10 for question style A (left) and question style B (right). Included is a line of the expected value &lt;span class=&#34;math inline&#34;&gt;\(\mathbb{E}(\text{no. of choices}) = np\)&lt;/span&gt;, plotted within a &lt;span class=&#34;math inline&#34;&gt;\(\pm 1.96 \cdot \sqrt{\sigma}\)&lt;/span&gt; confidence interval, where &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; is the binomial variance.
&lt;/figcaption&gt;
&lt;/center&gt;
&lt;/figure&gt;
&lt;p&gt;Surprisingly, both results are reasonably similar. Some statistics of these are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;4 is the most frequent number in both cases&lt;/strong&gt;, different from the usual value of 7 that has been in similar surveys before. In the comments for this survey, people seemed to expect 7 to be the most picked. It is possible that since the participants were aware of previous research in the area, they deliberately would not have picked 7.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The average ‘difference from uniformity’ was around 2.1% for both types of questions&lt;/strong&gt;. This is the percentage difference from the expected value.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;10.1% of people picked the same number for both questions&lt;/strong&gt;, and for true random number generation, the true value would be 10%!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The values at the edges, 1 and 10, were picked far less often&lt;/strong&gt; than values in the centre.&lt;/li&gt;
&lt;li&gt;The largest difference between questions was that &lt;strong&gt;10 was picked less in question type B than question type A&lt;/strong&gt;. A possible reason is that 10 is two digits long, which would require extra effort for question type B than for question type A.&lt;/li&gt;
&lt;li&gt;A Pearson’s &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; test for uniformity showed &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-values where &lt;span class=&#34;math inline&#34;&gt;\(p &amp;lt;&amp;lt; 0.0001\)&lt;/span&gt;, indicating with a reasonable level of certainty that &lt;strong&gt;neither sets of answers were uniformly distributed&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So people don’t seem to be entirely random in this case, but this is only one aspect of randomness. People picked the same number for both questions the correct amount of times! How about pairs of answers, i.e. for both &lt;em&gt;answer A&lt;/em&gt; and &lt;em&gt;answer B&lt;/em&gt;?&lt;/p&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;center&gt;
&lt;iframe height=&#34;350&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34; width=&#34;100%&#34; src=&#34;//plotly.com/~dannyjameswilliams/25.embed?autosize=true&amp;amp;link=false&amp;amp;modebar=false&#34;&gt;
&lt;/iframe&gt;
&lt;figcaption&gt;
Distribution of (&lt;em&gt;answer A&lt;/em&gt; - &lt;em&gt;answer B&lt;/em&gt;), plotted with the expected Irwin–Hall distribution.
&lt;/figcaption&gt;
&lt;/center&gt;
&lt;/figure&gt;
&lt;p&gt;If we subtract the answers from one another, we are essentially summing uniform random variables, which are expected to have a &lt;a href=&#34;https://en.wikipedia.org/wiki/Irwin%E2%80%93Hall_distribution&#34;&gt;Irwin-Hall distribution&lt;/a&gt;, or a triangular distribution when we are only summing two variables.&lt;/p&gt;
&lt;p&gt;Put simply, imagine you are rolling two six-sided dice. The most common sum of their values is 7, since there are more combinations that can sum to 7 than anything else. The same is true in this case, we expect the most common result of &lt;em&gt;answer A&lt;/em&gt; - &lt;em&gt;answer B&lt;/em&gt; to be 0, and then equally 1 and -1, and so on.&lt;/p&gt;
&lt;p&gt;Our distribution above actually does look similar to the expected triangular distribution (although we do have some oddities towards the centre of the triangle, likely caused by the lack of 1’s and 10’s). Does this mean human randomness isn’t too bad after all? In this aspect, we are quite good with the &lt;em&gt;pairs&lt;/em&gt; of our answers, even if our individual answers aren’t quite as good.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pick-a-random-letter-from-the-alphabet&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Pick a random letter from the alphabet&lt;/h2&gt;
&lt;p&gt;Okay, so we have trouble with edge effects - we don’t like to pick 1s and 10s when we are trying to randomly think of a number. What if we were to randomly select a letter? There’s no real intrinsic numeric value associated to a letter (unless you count its position in the alphabet), so maybe we are better at selecting a random letter. Let’s take a look.&lt;/p&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;center&gt;
&lt;iframe height=&#34;300&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34; width=&#34;90%&#34; src=&#34;//plotly.com/~dannyjameswilliams/62.embed?autosize=true&amp;amp;link=false&amp;amp;modebar=false&#34;&gt;
&lt;/iframe&gt;
&lt;figcaption&gt;
Frequency of chosen letters arranged alphabetically.
&lt;/figcaption&gt;
&lt;/center&gt;
&lt;/figure&gt;
&lt;p&gt;Ah, so we can’t select letters randomly either, but it doesn’t seem to depend on any sort of edge effects alphabetically. That is, people seem to pick A and Z a healthy amount. The frequencies for each letter are very far from what we’d expect if we were to have sampled these letters uniformly. What could have been affecting our judgement here? Maybe the popularity of a certain letter in the English language?&lt;/p&gt;
&lt;p&gt;Plotted below is the relationship between the &lt;em&gt;frequency at which a letter occurs in the English language&lt;/em&gt; (as a percentage) versus the &lt;em&gt;frequency it was picked in the survey&lt;/em&gt;.&lt;/p&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;center&gt;
&lt;iframe height=&#34;300&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34; width=&#34;90%&#34; src=&#34;//plotly.com/~dannyjameswilliams/23.embed?autosize=true&amp;amp;link=false&amp;amp;modebar=false&#34;&gt;
&lt;/iframe&gt;
&lt;figcaption&gt;
Letter percentage in the English Language plotted against the number of times the letter was picked in the survey. The red line is a line of best fit captured from a linear regression with a cubic polynomial transform on the English language percentage.
&lt;/figcaption&gt;
&lt;/center&gt;
&lt;/figure&gt;
&lt;p&gt;There is no significant relationship here, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value for a linear regression is very low, at &lt;span class=&#34;math inline&#34;&gt;\(R^2 \approx 0.152\)&lt;/span&gt;, meaning the model is not capturing the variability in the data. What else could be affecting how we are choosing these letters?&lt;/p&gt;
&lt;p&gt;Earlier I stated the assumption that there was no intrinsic numeric value associated to a letter, so that we would not have any trouble with edge effects skewing the results. That assumption was wrong! If you’re reading this on a computer or laptop, take a look what is just underneath your screen.&lt;/p&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;center&gt;
&lt;iframe height=&#34;180&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34; width=&#34;90%&#34; src=&#34;//plotly.com/~dannyjameswilliams/21.embed?autosize=true&amp;amp;link=false&amp;amp;modebar=false&#34;&gt;
&lt;/iframe&gt;
&lt;figcaption&gt;
Frequency of chosen letters as a heatmap overlaid on a keyboard.
&lt;/figcaption&gt;
&lt;/center&gt;
&lt;/figure&gt;
&lt;p&gt;It turns out that the most frequently picked letters are those that are most central on a QWERTY keyboard. This notion of picking the most central option is corroborated by the choice of number in the first question, being that people do not like to pick numbers or letters that appear on what they consider as the ‘edge’.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pick-a-random-number-between-1-and-50&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Pick a random number between 1 and 50&lt;/h2&gt;
&lt;p&gt;What if our selection range is so large that these edge effects can be nullified? If we ask people to select numbers between 1 and 50, will we see an extension of what we saw in the first question? I.e. are people going to pick the most central values again (say, between 10 and 40), or will it be something else?&lt;/p&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;center&gt;
&lt;iframe height=&#34;300&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34; width=&#34;90%&#34; src=&#34;//plotly.com/~dannyjameswilliams/19.embed?autosize=true&amp;amp;link=false&amp;amp;modebar=false&#34;&gt;
&lt;/iframe&gt;
&lt;figcaption&gt;
Frequency of chosen numbers between 1 and 50.
&lt;/figcaption&gt;
&lt;/center&gt;
&lt;/figure&gt;
&lt;p&gt;An interesting selection of numbers here. This range does not seem to be uniformly distributed in the slightest. Here are some facts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Against the expected value of 10%, only &lt;strong&gt;4.3% of people selected a multiple of 10&lt;/strong&gt;, whereas &lt;strong&gt;18.7% of people chose a number with a 7&lt;/strong&gt;, e.g. 17, 27 etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The lowest picked number was 30, by 0.5% of people&lt;/strong&gt;, and &lt;strong&gt;the highest picked number was 37, by 5.8% of people&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;Perhaps you remember the ‘trick’ that your friend would play on you as a kid in the playground. They would ask you a series of maths questions, and then ask you to &lt;em&gt;name a vegetable&lt;/em&gt;. You would inevitably say ‘carrot’, then they’d reveal a piece of paper with the word ‘carrot’ on it. Were you truly tricked? Turns out, if you’re asked to name a vegetable, &lt;a href=&#34;http://sciencechatforum.com/viewtopic.php?p=264070&#34;&gt;most people say carrot regardless&lt;/a&gt;. It’s not a trick, when asked to name something at random, we pick an extremely common vegetable.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Natural Language Analysis of the Lyrics of Kanye West</title>
      <link>https://dannyjameswilliams.co.uk/post/kanye/</link>
      <pubDate>Mon, 06 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://dannyjameswilliams.co.uk/post/kanye/</guid>
      <description>
&lt;script src=&#34;https://dannyjameswilliams.co.uk/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://dannyjameswilliams.co.uk/rmarkdown-libs/d3/d3.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://dannyjameswilliams.co.uk/rmarkdown-libs/forceNetwork-binding/forceNetwork.js&#34;&gt;&lt;/script&gt;


&lt;em&gt;“2020 I’mma run the whole election”&lt;/em&gt; may not sound like the words of a lyrical genius, but I ask you to &lt;em&gt;“name one genius that ain’t crazy”&lt;/em&gt;. For the duration of your read of this post, take a minute to separate an artist from their art. It is undeniable that Kanye West has had serious influence over the musical industry during his career. He has single-handedly influenced hip hop since his first album, &lt;em&gt;The College Dropout&lt;/em&gt;, and that’s not to mention &lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_awards_and_nominations_received_by_Kanye_West&#34;&gt;all of his awards&lt;/a&gt;.
&lt;br&gt;
&lt;br&gt;
&lt;center style=&#34;color:#717d7e;&#34;&gt;
&lt;em&gt;&amp;quot;I woke up early this mornin’ with a new state of mind&lt;/em&gt; &lt;br&gt;
&lt;em&gt;A creative way to rhyme without usin’ nines and guns&amp;quot;&lt;/em&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt;
Controversy aside, what makes Kanye West so influential to the hip-hop industry? His lyrics must play a part to his success. The &lt;a href=&#34;https://cloud.google.com/natural-language/&#34;&gt;Google Natural Language API&lt;/a&gt; can perform a full language analysis of Kanye West’s lyrics for free. This uses a pre-trained natural language model by Google, and the API is available for use in Python.&lt;/p&gt;
&lt;p&gt;The data were mostly obtained by using the &lt;a href=&#34;https://cran.r-project.org/web/packages/genius/index.html&#34;&gt;genius&lt;/a&gt; package in R, but missing entries were copied and pasted manually from the Genius website. The analysis is restricted to his studio albums, but not solo albums, so that his collaborations with Kid Cudi and Jay Z are included.
All albums considered are &lt;em&gt;The College Dropout&lt;/em&gt;, &lt;em&gt;Late Registration&lt;/em&gt;, &lt;em&gt;Graduation&lt;/em&gt;, &lt;em&gt;808’s &amp;amp; Heartbreak&lt;/em&gt;, &lt;em&gt;My Beautiful Dark Twisted Fantasy&lt;/em&gt;, &lt;em&gt;Watch the Throne&lt;/em&gt;, &lt;em&gt;Yeezus&lt;/em&gt;, &lt;em&gt;The Life of Pablo&lt;/em&gt;, &lt;em&gt;ye&lt;/em&gt;, &lt;em&gt;Kids See Ghosts&lt;/em&gt; and &lt;em&gt;Jesus is King&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This article is split into four sections:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Entity Analysis&lt;/li&gt;
&lt;li&gt;Sentiment Analysis&lt;/li&gt;
&lt;li&gt;Sentiment and Magnitude against Album Reception&lt;/li&gt;
&lt;li&gt;Generating a New Kanye Song&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All code used for the analysis and graphics in this post can be found in the github repository &lt;a href=&#34;https://github.com/dannyjameswilliams/kanyenet&#34;&gt;kanyenet&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;entity-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Entity Analysis&lt;/h2&gt;
&lt;p&gt;The natural language API provided by Google includes entity analysis - the identification of &lt;em&gt;entities&lt;/em&gt;, which can be interpreted as the ‘important parts’ of the text. Each song is passed individually to the API, collating the number of entities for each song. Below is a network of word connections, where the links between nodes represent words that appear in the same song. The graph is interactive, so you can scroll around and zoom in and out to see all the connections. You can click on a node to view the total number of times it appears across all songs.&lt;/p&gt;
It might take a while to load, and is best viewed on desktop. &lt;strong&gt;Content warning:&lt;/strong&gt; An effort has been made to censor offensive words, but some may have slipped through the cracks.
&lt;figure class=&#34;image&#34;&gt;
&lt;center&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:100%;height:480px;&#34; class=&#34;forceNetwork html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;links&#34;:{&#34;source&#34;:[0,0,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,4,5,5,5,5,5,5,5,5,5,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,9,9,9,10,10,10,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,14,14,14,14,14,14,15,15,15,15,15,15,16,16,16,16,16,16,17,17,17,18,18,18,19,19,19,19,19,19,19,19,19,19,20,20,21,21,22,22,23,23,23,23,23,23,23,24,24,25,25,25,25,26,26,27,27,27,27,27,28,28,28,28,28,29,29,29,29,29,29,29,29,30,30,30,31,31,32,32,33,33,33,33,33,33,33,33,33,33,33,34,34,34,34,34,34,34,34,34,34,35,35,36,36,36,36,36,36,36,36,37,37,37,37,37,37,38,39,39,39,40,41,41,41,41,41,41,41,42,42,42,42,42,42,42,42,42,42,43,43,43,43,43,43,43,43,43,44,45,46,46,47,48,48,48,49,49,49,49,49,50,50,50,51,51,51,51,52,52,52,53,53,53,53,53,54,54,54,54,55,55,55,56,56,56,56,57,57,57,57,58,58,58,58,59,59,60,60,60,61,61,61,61,61,61,61,61,61,61,61,61,61,61,62,62,62,62,62,62,62,62,62,63,63,63,63,63,63,63,63,64,64,65,65,65,65,65,65,65,66,66,67,67,67,67,67,68,68,68,68,68,68,69,69,69,69,70,71,71,71,71,71,71,71,71,71,71,72,72,72,72,72,73,73,74,74,74,75,75,75,75,76,77,77,78,79,80,80,80,80,80,80,81,81,82,83,83,83,83,83,83,83,83,83,83,83,84,84,85,85,86,86,86,86,87,87,87,87,88,89,89,89,89,89,89,89,89,89,89,90,90,90,90,91,91,92,92,92,92,92,93,93,94,95,95,95,96,96,97,98,98,98,98,98,98,98,98,98,98,98,98,98,98,99,100,100,100,100,100,101,102,103,103,104,104,105,106,107,108,108,108,109,109,109,109,109,109,109,110,110,110,111,111,111,111,112,112,113,113,113,113,113,114,114,115,116,116,116,116,116,116,116,116,116,116,117,117,117,117,117,117,118,119,119,119,120,120,121,121,122,123,124,125,125,125,125,125,125,125,125,125,125,126,127,127,128,128,129,129,129,129,129,130,130,130,131,132,133,134,135,135,136,137,138,139,139,139,139,139,139,140,140,140,141,141,141,142,143,144,145,146,147,148,148,149,149,150,150,151,152,153,154,155,156,157,157,158,159,160,161,162,163,164,164,165,166,167,168],&#34;target&#34;:[0,124,1,95,121,167,2,15,71,116,125,139,155,3,7,90,116,161,4,5,36,61,83,98,117,140,164,165,6,17,59,80,7,77,79,86,90,109,125,127,132,154,156,161,8,30,96,101,9,112,168,10,73,89,11,43,48,66,90,12,33,34,62,63,83,98,116,125,129,139,144,13,20,76,14,53,75,89,90,97,15,71,116,125,139,155,16,113,116,117,139,154,17,59,80,18,26,142,19,58,89,92,98,125,130,131,149,153,20,76,21,61,22,126,23,37,49,57,108,150,151,24,45,25,50,98,162,26,142,27,65,119,120,125,28,54,89,104,166,29,42,68,71,80,110,116,134,30,96,101,31,115,32,89,33,34,62,63,83,98,116,125,129,139,144,34,62,63,83,98,116,125,129,139,144,35,70,36,61,83,98,117,140,164,165,37,49,57,108,150,151,38,39,42,125,40,41,61,67,72,109,116,125,42,68,71,80,110,116,125,134,157,163,43,48,66,90,98,125,129,133,139,44,45,46,82,47,48,66,90,49,57,108,150,151,50,98,162,51,52,141,147,52,141,147,53,75,89,90,97,54,89,104,166,55,99,102,56,74,103,139,57,108,150,151,58,130,149,153,59,80,60,84,146,61,67,72,83,98,106,109,116,117,125,137,140,164,165,62,63,83,98,116,125,129,139,144,63,83,98,116,125,129,139,144,64,159,65,81,85,107,119,120,125,66,90,67,72,109,116,125,68,71,80,110,116,134,69,139,141,145,70,71,80,89,110,116,125,134,136,139,155,72,109,116,125,158,73,89,74,103,139,75,89,90,97,76,77,79,78,79,80,89,105,110,116,134,81,160,82,83,98,116,117,125,129,139,140,144,164,165,84,146,85,107,86,109,127,132,87,98,109,123,88,89,90,92,97,98,104,105,125,131,166,90,91,97,161,91,152,92,98,122,125,131,93,94,94,95,121,167,96,101,97,98,109,116,117,123,125,129,131,139,140,144,162,164,165,99,100,111,129,148,154,101,102,103,139,104,166,105,106,107,108,150,151,109,116,123,125,127,129,132,110,116,134,111,129,148,154,112,168,113,116,117,139,154,114,126,115,116,117,125,129,134,139,143,144,154,155,117,139,140,154,164,165,118,119,120,125,120,125,121,167,122,123,124,125,129,131,136,137,139,144,154,155,156,126,127,132,128,166,129,139,144,148,154,130,149,153,131,132,133,134,135,154,136,137,138,139,141,144,145,154,155,140,164,165,141,145,147,142,143,144,145,146,147,148,154,149,153,150,151,151,152,153,154,155,156,157,163,158,159,160,161,162,163,164,165,165,166,167,168],&#34;value&#34;:[1,2,1,2,2,2,1,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,1,2,2,2,6,2,2,2,2,2,2,2,2,2,2,2,1,2,2,2,1,2,2,1,2,2,1,2,2,2,2,4,4,4,4,4,4,4,8,4,4,4,4,1,2,2,2,2,2,2,2,2,1,2,2,2,2,2,1,2,2,2,2,2,1,2,2,1,2,2,2,2,2,2,2,2,2,2,2,2,1,2,1,4,1,2,1,2,2,2,2,2,2,1,2,1,2,2,2,1,2,1,2,2,2,2,1,2,2,2,2,1,2,2,2,2,2,2,2,1,2,2,1,2,1,2,1,2,2,2,2,2,4,2,2,2,2,1,2,2,2,2,4,2,2,2,2,1,2,1,2,2,2,2,2,2,2,1,2,2,2,2,2,1,1,2,2,1,1,2,2,2,2,2,2,3,2,2,2,2,2,2,2,2,2,5,2,2,2,2,2,2,2,2,1,1,1,2,1,2,2,2,1,2,2,2,2,1,2,2,1,2,2,2,1,2,2,1,2,2,2,2,1,2,2,2,2,2,2,1,2,2,2,1,2,2,2,1,2,2,2,1,2,1,2,2,8,2,2,2,2,2,2,2,2,4,2,2,2,2,1,2,2,2,4,2,2,2,2,1,2,2,4,2,2,2,2,1,2,5,2,2,2,2,2,2,1,2,1,2,2,2,2,1,2,2,2,2,2,1,2,2,2,1,5,2,2,2,4,4,2,2,2,2,2,2,2,2,2,1,2,1,2,2,1,2,2,2,1,1,2,2,1,3,2,2,2,2,2,3,2,1,3,4,4,2,2,2,2,2,2,2,2,1,2,1,2,1,2,2,2,1,2,2,2,1,8,2,2,2,2,2,2,4,2,2,4,2,2,2,2,2,3,2,2,2,2,1,2,1,1,2,2,1,2,1,8,4,4,2,2,6,4,2,2,2,2,2,2,2,1,1,2,2,2,2,1,1,1,2,1,2,1,1,1,1,2,2,4,2,2,2,2,2,2,1,2,2,1,2,2,2,1,2,1,2,2,2,2,1,2,1,17,2,8,4,2,8,2,4,2,2,2,2,2,2,2,2,1,1,2,2,1,2,1,2,1,3,1,14,2,2,2,2,4,2,2,2,2,2,1,2,1,2,4,4,2,2,2,1,2,2,1,1,2,1,1,4,1,1,1,6,2,2,2,2,2,1,2,2,2,2,2,1,1,1,1,1,1,1,2,1,2,1,2,1,1,1,8,1,1,1,2,1,1,1,3,1,1,1,2,1,2,1,1],&#34;colour&#34;:[&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;,&#34;#c2c2c2&#34;]},&#34;nodes&#34;:{&#34;name&#34;:[&#34;300&#34;,&#34;a million&#34;,&#34;air&#34;,&#34;all&#34;,&#34;america&#34;,&#34;ass&#34;,&#34;ayy&#34;,&#34;baby&#34;,&#34;baby jesus&#34;,&#34;ball&#34;,&#34;bang&#34;,&#34;beam&#34;,&#34;beat&#34;,&#34;big brother&#34;,&#34;bitch&#34;,&#34;bitches&#34;,&#34;blame game&#34;,&#34;bottle&#34;,&#34;bout&#34;,&#34;boy&#34;,&#34;brother&#34;,&#34;bulls***&#34;,&#34;c&#39;mon homie&#34;,&#34;cab&#34;,&#34;champion&#34;,&#34;chance&#34;,&#34;chill&#34;,&#34;church&#34;,&#34;city&#34;,&#34;concert&#34;,&#34;coretta&#34;,&#34;crack music n****&#34;,&#34;dad&#34;,&#34;dame&#34;,&#34;deal&#34;,&#34;dem&#34;,&#34;dessert&#34;,&#34;destination&#34;,&#34;diamond&#34;,&#34;door&#34;,&#34;dream&#34;,&#34;eighteen&#34;,&#34;everybody&#34;,&#34;everything&#34;,&#34;ey &#39;ey &#39;ey&#34;,&#34;eye&#34;,&#34;f***&#34;,&#34;fadin&#34;,&#34;faith&#34;,&#34;fare&#34;,&#34;fire&#34;,&#34;fly&#34;,&#34;fore&#34;,&#34;freak&#34;,&#34;freedom&#34;,&#34;friend&#34;,&#34;frightenin&#34;,&#34;front&#34;,&#34;gangsta&#34;,&#34;genie&#34;,&#34;ghost&#34;,&#34;girl&#34;,&#34;glass&#34;,&#34;glasses&#34;,&#34;glory&#34;,&#34;god&#34;,&#34;god dream&#34;,&#34;gold digger&#34;,&#34;gossip&#34;,&#34;graveshift&#34;,&#34;gwaan&#34;,&#34;hand&#34;,&#34;head&#34;,&#34;hell&#34;,&#34;help&#34;,&#34;highlight&#34;,&#34;hip hop brother&#34;,&#34;hoe&#34;,&#34;home&#34;,&#34;homie&#34;,&#34;i&#39;ma&#34;,&#34;jesus&#34;,&#34;jungle&#34;,&#34;kanye&#34;,&#34;kid&#34;,&#34;king&#34;,&#34;l.a.&#34;,&#34;la la&#34;,&#34;lie&#34;,&#34;life&#34;,&#34;light&#34;,&#34;lord&#34;,&#34;love&#34;,&#34;love lock-down&#34;,&#34;love lockdown&#34;,&#34;luxury&#34;,&#34;malcolm&#34;,&#34;mama&#34;,&#34;man&#34;,&#34;many&#34;,&#34;mars&#34;,&#34;martin&#34;,&#34;memorie&#34;,&#34;menacin&#34;,&#34;mind&#34;,&#34;mine&#34;,&#34;mistake&#34;,&#34;mob&#34;,&#34;moment&#34;,&#34;money&#34;,&#34;monster&#34;,&#34;moon&#34;,&#34;mothaf***a&#34;,&#34;motherf***er&#34;,&#34;murder&#34;,&#34;music&#34;,&#34;n****&#34;,&#34;name&#34;,&#34;new&#34;,&#34;night sky&#34;,&#34;nightlife&#34;,&#34;nike&#34;,&#34;nobody&#34;,&#34;nothing&#34;,&#34;omen&#34;,&#34;one&#34;,&#34;paper&#34;,&#34;parties&#34;,&#34;party&#34;,&#34;people&#34;,&#34;pimp&#34;,&#34;pinocchio&#34;,&#34;place&#34;,&#34;power&#34;,&#34;profit&#34;,&#34;rain&#34;,&#34;reason&#34;,&#34;robocop&#34;,&#34;rosie&#34;,&#34;s***&#34;,&#34;salad&#34;,&#34;sky&#34;,&#34;slave&#34;,&#34;somebody&#34;,&#34;song&#34;,&#34;spaceship&#34;,&#34;spirit&#34;,&#34;spot&#34;,&#34;star&#34;,&#34;step&#34;,&#34;street&#34;,&#34;street light&#34;,&#34;stress&#34;,&#34;talk&#34;,&#34;thing&#34;,&#34;thirty&#34;,&#34;toast&#34;,&#34;two&#34;,&#34;vision&#34;,&#34;war&#34;,&#34;water&#34;,&#34;way&#34;,&#34;wire&#34;,&#34;word&#34;,&#34;work&#34;,&#34;workout plan&#34;,&#34;world&#34;,&#34;yeezy&#34;,&#34;zone&#34;],&#34;group&#34;:[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169],&#34;nodesize&#34;:[6,5,12,14,7,7,8,49,6,6,5,6,14,14,20,5,11,6,5,15,6,9,11,5,9,6,8,11,6,9,5,19,5,7,7,12,5,5,8,5,5,5,20,42,12,7,5,8,10,5,9,8,8,6,8,16,6,5,6,6,22,64,8,9,8,52,9,8,6,8,6,45,21,5,6,6,6,8,19,22,23,29,7,41,21,6,13,9,8,50,42,27,25,12,9,11,6,6,62,6,5,6,5,6,5,6,10,6,5,27,12,9,7,6,17,12,84,21,9,13,5,5,15,27,5,97,10,12,10,29,6,5,5,16,7,6,6,8,7,54,5,19,7,5,5,10,6,8,9,24,6,5,9,6,72,5,15,15,7,8,12,18,5,12,6,8,11,16,9],&#34;size&#34;:[6,5,12,14,7,7,8,49,6,6,5,6,14,14,20,5,11,6,5,15,6,9,11,5,9,6,8,11,6,9,5,19,5,7,7,12,5,5,8,5,5,5,20,42,12,7,5,8,10,5,9,8,8,6,8,16,6,5,6,6,22,64,8,9,8,52,9,8,6,8,6,45,21,5,6,6,6,8,19,22,23,29,7,41,21,6,13,9,8,50,42,27,25,12,9,11,6,6,62,6,5,6,5,6,5,6,10,6,5,27,12,9,7,6,17,12,84,21,9,13,5,5,15,27,5,97,10,12,10,29,6,5,5,16,7,6,6,8,7,54,5,19,7,5,5,10,6,8,9,24,6,5,9,6,72,5,15,15,7,8,12,18,5,12,6,8,11,16,9]},&#34;options&#34;:{&#34;NodeID&#34;:&#34;name&#34;,&#34;Group&#34;:1,&#34;colourScale&#34;:&#34;d3.scaleOrdinal(d3.schemeCategory20);&#34;,&#34;fontSize&#34;:18,&#34;fontFamily&#34;:&#34;Calibri&#34;,&#34;clickTextSize&#34;:45,&#34;linkDistance&#34;:&#34;function(d){return d.value * 10}&#34;,&#34;linkWidth&#34;:&#34;function(d) { return Math.sqrt(d.value); }&#34;,&#34;charge&#34;:-150,&#34;opacity&#34;:0.9,&#34;zoom&#34;:true,&#34;legend&#34;:false,&#34;arrows&#34;:false,&#34;nodesize&#34;:true,&#34;radiusCalculation&#34;:&#34; Math.sqrt(d.nodesize)+6&#34;,&#34;bounded&#34;:false,&#34;opacityNoHover&#34;:0.15,&#34;clickAction&#34;:&#34;alert(\&#34;Total count of &#39;\&#34; + (d.name) + \&#34;&#39;: \&#34; + (d.size) + \&#34;\n\&#34;)&#34;}},&#34;evals&#34;:[&#34;options.linkDistance&#34;],&#34;jsHooks&#34;:{&#34;render&#34;:[{&#34;code&#34;:&#34;function(el, x) { \n    d3.selectAll(\&#34;.node text\&#34;).style(\&#34;fill\&#34;, \&#34;black\&#34;);\n  }&#34;,&#34;data&#34;:null}]}}&lt;/script&gt;
&lt;figcaption&gt;
Network of entities. Connections between nodes represent entities being in the same song.
&lt;/figcaption&gt;
&lt;/center&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br&gt;
To see a larger version of this network, with the ability to filter by album and minimum number of occurences of a word, &lt;a href=&#34;https://dannyjameswilliams.shinyapps.io/kanyenetwork/&#34;&gt;click here to view it as an R shiny app.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This graph only contains entities that appear more than 4 times across all songs, as the full network would contain far too much information, and nothing would be visible. The larger size of the node indicates a word being more frequent across all songs.&lt;/p&gt;
&lt;p&gt;Since this undirected graph is &lt;em&gt;not fully connected&lt;/em&gt;, then it is impossible to connect all entities to each other via other entities that appear in the same song. Here we can also see the most common words at the center of the graph, and as expected, the most frequent words also seem to have the most connections.&lt;/p&gt;
&lt;p&gt;We can also note a few interesting qualities; firstly that Kanye never talks about Jesus in a song without also talking about God. Secondly, Kanye only talks about mistakes when he also talks about girls, I wonder what could that mean?&lt;/p&gt;
&lt;p&gt;Themes are also apparent in different clusters of the graph, for example, a small section containing &lt;em&gt;star&lt;/em&gt;, &lt;em&gt;moon&lt;/em&gt; and &lt;em&gt;mars&lt;/em&gt;, or entities such as &lt;em&gt;workout plan&lt;/em&gt;, &lt;em&gt;dessert&lt;/em&gt; and &lt;em&gt;salad&lt;/em&gt; in another section, seemingly referring to exercise and health. Particular songs can also be isolated out at the outer sections of the graph, which explains some of the more uncommon words that appear with few connections.&lt;/p&gt;
&lt;p&gt;But how do the frequency of these entities change over time? We can inspect the top 10 entities separately for each album, which gives a good indication of their individual themes, as well as Kanye’s use of different lyricism throughout his career.&lt;/p&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;center&gt;
&lt;img src=&#34;https://dannyjameswilliams.co.uk/img/post/kanye/top10words_notitles.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;
&lt;figcaption&gt;
Top 10 entities by album in order of their release.
&lt;/figcaption&gt;
&lt;/center&gt;
&lt;/figure&gt;
&lt;p&gt;Kanye’s albums have a broad range of different themes, which correspond to different entities being more prevalent within them. Kanye’s most heartfelt album, &lt;em&gt;808’s &amp;amp; Heartbreak&lt;/em&gt; (the fourth album) contained no curse words, but instead had more references to ‘love’ and ‘life’. It is easy to judge the theme of each album by their most common entities, such as &lt;em&gt;Jesus is King&lt;/em&gt; (the final one). Again there are no profanities, instead the album is heavily focused on religion, being a gospel album. Here, ‘Jesus’ is the most common entity, followed by god.&lt;/p&gt;
Some of the entities which might seem ‘irrelevant’ that can be found within these charts often correspond to a single song with purposeful repetition. ‘Toast’ appears in the top 10 entities for the album &lt;em&gt;My Beautiful Dark Twisted Fantasy&lt;/em&gt;, not because it is an amazing breakfast food, but because it is repeated in the chorus of &lt;em&gt;Runaway&lt;/em&gt;.
&lt;br&gt;
&lt;br&gt;
&lt;center style=&#34;color:#717d7e;&#34;&gt;
&lt;em&gt;“Let’s have a toast for the douche bags, let’s have a toast for the assholes,&lt;em&gt;&lt;br&gt;
&lt;/em&gt;Let’s have a toast for the scumbags, every one of them that I know”&lt;/em&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;As a side note, you may wonder why the word ‘amazing’ does not appear in the top 10 entities for &lt;em&gt;808’s &amp;amp; Heartbreak&lt;/em&gt;, due to it appearing a whopping 55 times in the song &lt;em&gt;Amazing&lt;/em&gt;. Thankfully, Google’s API does not classify it as an entity, since it is actually an adjective. However, ‘love lockdown’ and ‘robocop’ still made it through, as both words are repeated many times in their own songs.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sentiment-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sentiment Analysis&lt;/h2&gt;
&lt;p&gt;Natural language analysis can also classify the &lt;em&gt;sentiment&lt;/em&gt; of a piece of text, in this case, the sentiment of song lyrics, one song at a time. The sentiment ranges from -1 to 1, where a negative/positive value means the song has a lower/higher sentiment, generally referring to the mood of the song - whether it is more uplifting or sad.&lt;/p&gt;
&lt;p&gt;Firstly, the sentiment API extracts the sentiment from each sentence separately. We can take a look at the density of all sentence sentiments below.&lt;/p&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;center&gt;
&lt;img src=&#34;https://dannyjameswilliams.co.uk/img/post/kanye/sentiment_density.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;
&lt;figcaption&gt;
Density of sentence sentiment.
&lt;/figcaption&gt;
&lt;/center&gt;
&lt;/figure&gt;
&lt;p&gt;So most of the sentence sentiments are negative, in general Kanye’s lyrics convey a more sombre tone than they do a positive one. Wording can play a key part in how the natural language analysis measures sentiment. The lowest sentiment sentences are at -0.9, so let’s take a look at some examples of these.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;“Oh, how could you be so heartless?”&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;“The devil is alive I feel him breathing.”&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;“And when I’m older, you ain’t gotta work no more.”&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can see the first two generally are quite negative, but the last one has been misrepresented. In this line, Kanye talks about when he was a kid, he wanted to take care of his mother when she got older so that she wouldn’t have to go to work again, but the syntax of the sentence tricked the API into believing it was a generally negative sentence. This isn’t very common, but does highlight one of the limitations of this natural language API.&lt;/p&gt;
&lt;p&gt;A song’s &lt;em&gt;magnitude&lt;/em&gt; is defined as the sum of the absolute values of the sentiments for each sentence in the song. Quite a mouthful - consider it as the ‘emotionality’ of the song; the higher the sentiment is (in one way or another), the more emotional the song becomes. We can break down the sentiment and magnitude over all songs by album.&lt;/p&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;center&gt;
&lt;img src=&#34;https://dannyjameswilliams.co.uk/img/post/kanye/sentiment_magnitude.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;
&lt;figcaption&gt;
Sentiment (top) and magnitude (bottom), averaged for each song and split by album.
&lt;/figcaption&gt;
&lt;/center&gt;
&lt;/figure&gt;
&lt;p&gt;Generally, Kanye’s albums are all quite negative, with the exception of &lt;em&gt;Kids See Ghosts&lt;/em&gt; and &lt;em&gt;Jesus is King&lt;/em&gt;, his two latest albums. After the release of &lt;em&gt;Graduation&lt;/em&gt;, Kanye went through various personal traumas. We can see this reflected here, as the sentiment up to &lt;em&gt;Graduation&lt;/em&gt; was increasing, after which it began decreasing again. Only recently has the sentiment began to increase again.&lt;/p&gt;
&lt;p&gt;The album with the lowest sentiment is &lt;em&gt;Yeezus&lt;/em&gt;, which surprisingly does not have the largest magnitude, although the magnitude does not vary as much with album. The sentiment in &lt;em&gt;808’s &amp;amp; Heartbreak&lt;/em&gt; has the largest variance, with certain songs reaching very low and (comparatively) high values. These two albums generally are considered quite emotional, so it is reassuring to see this reflected in the sentiment analysis.&lt;/p&gt;
&lt;p&gt;We might say that it’s nice that Kanye’s latest releases are more positive, but there is a general attitude of &lt;em&gt;“I miss the old Kanye”&lt;/em&gt;. Is that the lower mood Kanye? The always rude Kanye?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sentiment-and-magnitude-against-album-reception&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sentiment and Magnitude against Album Reception&lt;/h2&gt;
&lt;p&gt;The next question in our heads should be, what can we infer from this? Some albums have a higher or lower sentiment than others, but does this have any relationship with the album itself?&lt;/p&gt;
&lt;p&gt;It turns out: well, maybe. Plotted below are the relationships between the mean sentiment and the mean magnitude, by album, against the aggregated critic reviews for each album collected from &lt;a href=&#34;https://www.metacritic.com/person/kanye-west&#34;&gt;Metacritic&lt;/a&gt;.&lt;/p&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;center&gt;
&lt;iframe height=&#34;450&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34; width=&#34;100%&#34; src=&#34;//plotly.com/~dannyjameswilliams/3.embed?autosize=true&amp;amp;link=false&amp;amp;modebar=false&#34;&gt;
&lt;/iframe&gt;
&lt;figcaption&gt;
Linear regression for Album sentiment against metacritic score.
&lt;/figcaption&gt;
&lt;/center&gt;
&lt;/figure&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;center&gt;
&lt;iframe width=&#34;100%&#34; height=&#34;450&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34; src=&#34;//plotly.com/~dannyjameswilliams/6.embed?autosize=true&amp;amp;link=false&amp;amp;modebar=false&#34;&gt;
&lt;/iframe&gt;
&lt;figcaption&gt;
Linear regression for Album magnitude against metacritic score.
&lt;/figcaption&gt;
&lt;/center&gt;
&lt;/figure&gt;
&lt;p&gt;Linear regression models are chosen because of the sparsity of data. Any more complex model is likely unneeded, but would also lack sufficient degrees of freedom to perform any meaningful inference. Modelling these variables separately allowed for more succinct visualisation and interpretation of their effects in isolation. The goodness of fit for each model can be evaluated somewhat with &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; values:
&lt;span class=&#34;math display&#34;&gt;\[
R^2_{\text{sentiment}} \approx  0.270, \qquad R^2_{\text{magnitude}} \approx  0.675.
\]&lt;/span&gt;
So the model involving each album’s mean magnitude explains more of the variance than the sentiment, and there is some definite correlation there. Does this mean an album with a higher magnitude (i.e. contains more emotional lyrics) will be more critically acclaimed? I can’t say for sure, but it’s an interesting point to note.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;generating-a-new-kanye-song&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Generating a New Kanye Song&lt;/h2&gt;
&lt;p&gt;Finally, I would like to end this post by creating the lyrics for a new Kanye song. &lt;a href=&#34;https://openai.com/blog/better-language-models/&#34;&gt;OpenAI’s unsupervised GPT-2 language model&lt;/a&gt; was trained on 40GB of internet text, and tasked with predicting the next word given in the text. The model contains an amazing 1.5 billion parameters. The &lt;a href=&#34;https://github.com/minimaxir/gpt-2-simple&#34;&gt;gpt-2-simple&lt;/a&gt; package in Python provides straightforward access to finetuning the GPT-2 model to an additional dataset, so that text generations are based on the new data, but the language has already been learned from the 40GB of internet text (if you think GPT-2 is impressive, take a look at &lt;a href=&#34;https://arxiv.org/abs/2005.14165&#34;&gt;GPT-3&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;I input the formatted lyric text file to finetune the GPT-2 model to Kanye’s lyrics, and generated many large sized texts to be considered as songs. This was done in Google colab notebooks, and the code used to do so is &lt;a href=&#34;https://colab.research.google.com/drive/13tC0RIr_IpNNWr6zInYkyormDgKsyF18?usp=sharing&#34;&gt;available here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Of the songs generated, I picked a coherent and ‘song-like’ generation and changed the formatting (added spacing). I hope you enjoy the latest release!&lt;/p&gt;
&lt;center style=&#34;color:#717d7e;&#34;&gt;
My name is Bess, I’m 21 years old and I just want to be a real star&lt;br&gt;
I just want to be a superstar&lt;br&gt;
The city skyline, the planes flying overhead&lt;br&gt;
I’m groovy as f***, like Good Charlotte&lt;br&gt;
Uh, and I just want my daddy to be proud of me&lt;br&gt;
&lt;br&gt;
Cause I ain’t talkin’ about Kris when it comes to being in the club&lt;br&gt;
It’s Jay that I’m talkin’ about, man&lt;br&gt;
Even though he got the baby’s clothes on&lt;br&gt;
I done wore nothing but red until he tucked me in&lt;br&gt;
And when he woke up, I was still wearing everything buterin’&lt;br&gt;
S*** was very “The Big Lebowski”&lt;br&gt;
&lt;br&gt;
I was standin’ by myself writing this song&lt;br&gt;
And I just started to cry&lt;br&gt;
Because this s*** can’t get any worse&lt;br&gt;
This s*** can’t get any worse&lt;br&gt;
Oh, Lord, oh, Lord&lt;br&gt;
&lt;br&gt;
I’m comin’, I’m comin’ in, load ya weapons&lt;br&gt;
I’m comin’, I’m comin’ in, load ya weapons&lt;br&gt;
I’m comin’, I’m comin’ in, load ya weapons&lt;br&gt;
I’m comin’, I’m comin’ in, load ya weapons&lt;br&gt;
&lt;br&gt;
And I came back, I came back, I came back&lt;br&gt;
And I looked in the mirror and I seen the biggest&lt;br&gt;
The guns are in the table, the weapons is in the air&lt;br&gt;
&lt;br&gt;
Yeah, make America great again&lt;br&gt;
Keep America great again&lt;br&gt;
Keep America great again&lt;br&gt;
Keep America great again&lt;br&gt;
Keep America great again&lt;br&gt;
Keep America great again&lt;br&gt;
Keep America great again&lt;br&gt;
&lt;br&gt;
&lt;/center&gt;
&lt;p&gt;Seems to match Kanye pretty well, we have mention of his mother-in-law, Kris Jenner, as well as his sort-of friend and collaborator Jay-Z. Then we finish with a classic controversial Kanye segment.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;interactive-visualisations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Interactive Visualisations&lt;/h2&gt;
&lt;p&gt;Most of the visualisations that I have shown can be found in an R shiny app below.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://dannyjameswilliams.shinyapps.io/kanyenet/&#34;&gt;The kanyenet interactive R shiny app.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Also included are additional interactive plots, enabling the filtering by album for sentiment densities and viewing the sentiment and magnitude of each song. You can also view more generations from the GPT-2 model!&lt;/p&gt;
&lt;p&gt;Again, you can view all code used for this report in the github repository &lt;a href=&#34;https://github.com/dannyjameswilliams/kanyenet&#34;&gt;kanyenet&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Exploring Natural Language Embeddings of A Game of Thrones</title>
      <link>https://dannyjameswilliams.co.uk/post/asoiaf/</link>
      <pubDate>Tue, 10 Jan 2012 00:00:00 +0000</pubDate>
      <guid>https://dannyjameswilliams.co.uk/post/asoiaf/</guid>
      <description>
&lt;script src=&#34;https://dannyjameswilliams.co.uk/post/asoiaf/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;For those of you familiar with either HBO’s Game of Thrones, or George RR Martin’s A Song of Ice and Fire (ASOIAF), you will probably be aware of the vast differences between each character and the depth of each storyline. For those of you who aren’t familiar; each book chapter is written from the perspective of a different character, and George RR Martin writes each character in a distinct and unique way. A chapter written from the perspective of Eddard Stark, an aged and grizzled war veteran, will be portrayed vastly different to a chapter from the perspective of his son, Bran Stark, a 9 year old innocent ‘sweet summer child’.&lt;/p&gt;
&lt;p&gt;The stories surrounding all of the characters span continents, explore diverse themes and face different problems, and so we would expect there to be intrinsic differences between the language used for all of these different perspectives. &lt;em&gt;Can we use Natural Language Processing (NLP) to show how George RR Martin writes each of these characters?&lt;/em&gt; More specifically, is there actually a &lt;em&gt;mathematical difference&lt;/em&gt; between the chapters, grouped by character, based on the language alone?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A note on spoilers&lt;/strong&gt;: I am not including any excerpts from either the books or the show, and do not discuss the story. However, you will be able to see how many chapters are included for each character, as well as if any characters &lt;em&gt;stop&lt;/em&gt; having point-of-view chapters after a specific book.&lt;/p&gt;
&lt;div id=&#34;what-are-bert-embeddings&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What are BERT Embeddings?&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1810.04805.pdf&#34;&gt;Bidirectional Encoder Representations from Transformers&lt;/a&gt;, or BERT for short, is a NLP model built by Google, an extremely powerful tool which can output &lt;em&gt;sentence embeddings&lt;/em&gt;. Put simply, a sentence embedding is a sequence of words, e.g. a sentence, which has been converted to a very high-dimensional mathematical vector. The vector itself won’t have any meaning to you or I on its own, but it has context relative to other sentences. For example, if two different sentence embeddings are very far away from each other, we can probably infer that the two original sentences are quite different.&lt;/p&gt;
&lt;p&gt;BERT can achieve this as it has been trained on a large corpus of language data: &lt;a href=&#34;https://arxiv.org/pdf/1506.06724.pdf&#34;&gt;a dataset of books&lt;/a&gt; and the full English Wikipedia. One way in which BERT trains is by &lt;em&gt;masked language modelling&lt;/em&gt;, which masks words at random, then tries to predict that masked word using the ‘transformer’ architecture, which is an extremely clever way of incorporating left-to-right and right-to-left directionality in a sentence so that the full context of the word is used. Essentially, BERT is an AI model that can give us a lot of information about language based on historical data from books and the internet.&lt;/p&gt;
&lt;p&gt;Fortunately for us, BERT is made completely open-source and free to use via &lt;a href=&#34;https://huggingface.co/bert-base-uncased&#34;&gt;Huggingface&lt;/a&gt;, a collection of NLP models, datasets, and more.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;asoiaf-embeddings&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;ASOIAF Embeddings&lt;/h1&gt;
&lt;p&gt;We can give BERT a sentence from ASOIAF, and it will output a relevant vector which gives information about this sentence. Repeating this for every sentence in the ASOIAF book series, we can obtain the high-dimensional sentence embeddings from each chapter of ASOIAF, by grouping by chapter and taking the average embedding across sentences.&lt;/p&gt;
&lt;p&gt;The embedding dimension output given by the base BERT model is 768, which we definitely cannot visualise. For this reason I have used &lt;a href=&#34;https://umap-learn.readthedocs.io/en/latest/&#34;&gt;UMAP&lt;/a&gt;&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;, a low-dimension projection method, to reduce the dimension to 3 so that we can visualise it.&lt;/p&gt;
&lt;div id=&#34;separation-by-character&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Separation by Character&lt;/h2&gt;
&lt;p&gt;Below I have plotted the (now 3D) embeddings in an interactive scatter plot, which you can rotate and move around. You can hover over each point to see the point-of-view character for each chapter and the corresponding book, as well as click on character names on the legend to remove them.&lt;/p&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;center&gt;
&lt;iframe height=&#34;750&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34; width=&#34;100%&#34; src=&#34;//plotly.com/~dannyjameswilliams/169.embed?autosize=true&amp;amp;link=false&amp;amp;modebar=false&#34;&gt;
&lt;/iframe&gt;
&lt;figcaption&gt;
Mean BERT sentence embeddings of chapters in ASOIAF, split by character (with each book labelled), restricted to the 10 most frequently occuring point-of-view characters. The dimension was reduced from 768 to 3 using UMAP. &lt;a href=&#34;https://chart-studio.plotly.com/~dannyjameswilliams/169/#/&#34;&gt;See in fullscreen here&lt;/a&gt;.
&lt;/figcaption&gt;
&lt;/center&gt;
&lt;/figure&gt;
&lt;p&gt;It is important to note that &lt;em&gt;no information about the classes (chapters/characters) was used at any point&lt;/em&gt;, so any structure we can see that separates the different characters or chapters is purely based on the language alone. The factors that could influence this are, for example: word choice, writing style, sentence length, and more.&lt;/p&gt;
&lt;p&gt;So what can we infer from this? The key aspects we are looking for are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How clustered are chapters from the same character?&lt;/li&gt;
&lt;li&gt;How separated are chapters from different characters?&lt;/li&gt;
&lt;li&gt;Are similar characters close to one another?&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;my-interpretation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;My Interpretation&lt;/h3&gt;
&lt;p&gt;From what I can see, the honourable and consistent Eddard Stark occupies a distinct region of the plot, and doesn’t stray far from it, but he is joined by other chapters from the first book. Daenerys’s storyline is mostly separated from the rest of the characters, so it makes sense that her chapters are grouped together and distinct in the plot. Other characters, such as Arya, seem to be uniquely identifiable due to being separated from the other clusters. The questionably lovable dwarf, Tyrion, has a plotline which spans battlefields, court intrigue, romance, death, and more. This seems to be shown here by his embeddings being spread across the entire space, representing the large variability in his changing viewpoints and scenarios.&lt;/p&gt;
&lt;p&gt;Surprisingly, I expected the child characters, most notably Sansa and Bran, to occupy a distinct region because of their naive and childlike viewpoints, but their distributions aren’t too different from most other characters. In fact, Jon’s and Bran’s chapters seem to exist in the same regions of the plot, which could indicate a similarity in the characters, or at least how the characters are written.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;separation-by-book&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Separation by Book&lt;/h2&gt;
&lt;p&gt;There seems to be a divide based on the book which each chapter is written in. Just by switching the labels (and removing the top 10 character restriction), we can inspect the same plot with a different angle.&lt;/p&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;center&gt;
&lt;iframe height=&#34;750&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34; width=&#34;100%&#34; src=&#34;//plotly.com/~dannyjameswilliams/171.embed?autosize=true&amp;amp;link=false&amp;amp;modebar=false&#34;&gt;
&lt;/iframe&gt;
&lt;figcaption&gt;
Mean BERT sentence embeddings of chapters in ASOIAF, split by book. The dimension was reduced from 768 to 3 using UMAP. &lt;a href=&#34;https://chart-studio.plotly.com/~dannyjameswilliams/171/#/&#34;&gt;See in fullscreen here&lt;/a&gt;.
&lt;/figcaption&gt;
&lt;/center&gt;
&lt;/figure&gt;
&lt;p&gt;The divide between classes is far more clear in this case&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; - books 2 and 3 (ACOK and ASOS respectively), are far, far, different from the other books in the series. The first, fourth and fifth books (AGOT, AFFC and ADWD respectively), are more closely related, with the first book being in a more distinctive class. Books 4 and 5 were written at the same time, which might explain their embeddings being so intertwined.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;final-thoughts&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Final Thoughts&lt;/h1&gt;
&lt;p&gt;It is interesting how we can &lt;em&gt;mathematically see the difference in language&lt;/em&gt; based on the book or the character. There is a clear mathematical distinction between writing styles used for different characters, and we have even shown the evolution of George RR Martin’s prose over the course of writing the ASOIAF series.&lt;/p&gt;
&lt;p&gt;We can see the potential usefulness of these BERT embeddings, and they have far more use outside of plotting them to see their groups. We could’ve calculated the distance between embeddings to see exactly which characters are the most different or the most similar. We could use the embeddings themselves in a data science application; for example, how well can we classify which character is being written about based on only language?&lt;/p&gt;
&lt;p&gt;Existing research in NLP has given us the avenue to do all of this. It is an extremely interesting field, and is constantly developing. The methods we used here are free, and open to anyone for experimenting with. What other applications do you think would be cool to see? If you would like to ask any questions or have any discussion, &lt;a href=&#34;https://dannyjameswilliams.co.uk/#contact&#34;&gt;see my contact page&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;The UMAP transform was fit with hyperparameters &lt;code&gt;min_dist = 0&lt;/code&gt; and &lt;code&gt;n_neighbors = 30&lt;/code&gt;, chosen by trial and error, to try to separate the classes as much as possible. All other values were kept as default in &lt;a href=&#34;https://umap-learn.readthedocs.io/en/latest/api.html#umap&#34;&gt;this function&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;For completeness, here are the initialisms used for each book. AGOT: A Game of Thrones, ACOK: A Clash of Kings, ASOS: A Storm of Swords, AFFC: A Feast for Crows, ADWD: A Dance with Dragons&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
